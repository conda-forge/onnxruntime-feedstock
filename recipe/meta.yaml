{% set name = "onnxruntime" %}
{% set cuda_enabled = cuda_compiler_version != "None" %}
{% set build_ext = "cuda" if cuda_enabled else "cpu" %}
{% set version = "1.20.1" %}
{% set suffix = "" %}  # [suffix == None]
{% set build = 1 %}

{% if cuda_enabled %}
{% set build = build + 200 %}
{% endif %}

{% if cuda_compiler_version in (None, "None", True, False) %}
{% set cuda_major = 0 %}
{% else %}
{% set cuda_major = environ.get("cuda_compiler_version", "11.8").split(".")[0] | int %}
{% endif %}

package:
  name: {{ name|lower }}{{ suffix }}
  version: {{ version }}

source:
  - url: https://github.com/microsoft/onnxruntime/archive/refs/tags/v{{ version }}.tar.gz
    sha256: d4c005506a2bbf88a838b14f8d1578406b8be2fb64abb50beeff908fb272529e
    patches:
      - dont-call-pip-on-win.patch
      # Workaround for https://github.com/conda-forge/onnxruntime-feedstock/pull/56#issuecomment-1586080419
      - windows_workaround_conflict_onnxruntime_dll_system32.patch  # [win]
      - cxx_17_for_darwin.patch
      # Workaround for https://github.com/conda-forge/onnxruntime-feedstock/pull/115#issuecomment-2122077816
      - do_not_pass_msvc_style_definitions_to_nvcc.patch  # [win]

      # https://github.com/conda-forge/onnxruntime-feedstock/pull/128#issuecomment-2390332504
      - use_first_nvcc_found.patch

      # Improve compatibility between Visual Studio 19.41 + cuda 12.0 (they require 12.4 by default)
      # Upstream suggestion https://github.com/microsoft/onnxruntime/pull/22332
      - 22332.patch

build:
  number: {{ build }}
  # no windows user has requested novec (yet)
  skip: true  # [win and suffix == "-novec"]
  # Since 1.11, power9 seems to be required.
  skip: true  # [ppc64le]
  skip: true  # [cuda_compiler_version == "11.2"]
  # 2024/11/22 -- hmaarrfk -- cuda 11.8 will need a champion to fix compilation issues
  skip: true  # [cuda_compiler_version == "11.8"]
  skip: true  # [py<310]
  string: py{{ CONDA_PY }}h{{ PKG_HASH }}_{{ PKG_BUILDNUM }}_{{ build_ext }}
  ignore_run_exports_from:
    - zlib
  # This needs to be coherent with the entry_points list defined around
  # https://github.com/microsoft/onnxruntime/blob/main/setup.py#L735
  entry_points:
    - onnxruntime_test = onnxruntime.tools.onnxruntime_test:main

requirements:
  build:
    - python                                 # [build_platform != target_platform]
    - cross-python_{{ target_platform }}     # [build_platform != target_platform]
    - numpy                                  # [build_platform != target_platform]
    - pybind11                               # [build_platform != target_platform]
    - {{ compiler('c') }}
    - {{ stdlib('c') }}
    - {{ compiler('cxx') }}
    - {{ compiler('cuda') }}  # [cuda_compiler_version != "None"]
    {% if cuda_major >= 12 %}
    - cuda-cudart-dev                        # [build_platform != target_platform]
    - cuda-nvrtc-dev                         # [build_platform != target_platform]
    {% endif %}
    - cmake
    - ninja
    # we need protoc in the build environment for cross compilations
    - libprotobuf 3.21
  host:
    - python
    - pip
    - setuptools
    - wheel
    - cudnn                                     # [cuda_compiler_version != "None"]
    - cuda-version {{ cuda_compiler_version }}  # [cuda_compiler_version != "None"]
    {% if cuda_major >= 12 %}
    - libcublas-dev
    - libcusparse-dev
    - libcurand-dev
    - libcufft-dev
    - cuda-cudart-dev
    - cuda-nvrtc-dev
    {% endif %}
    - flake8
    - gmock
    - libdate
    - packaging
    - python-flatbuffers
    - optional-lite
    - zlib
    - numpy
    - pybind11
  run:
    - coloredlogs
    - packaging
    - protobuf
    - python
    - python-flatbuffers
    - sympy
    # avoid that people without GPUs needlessly download ~0.5-1GB
    - __cuda                                    # [cuda_compiler_version != "None"]
  run_constrained:
    - onnxruntime <0a0  # [suffix == "-novec"]

test:
  imports:
    - onnxruntime
  commands:
    - pip check
    - onnxruntime_test --help
  requires:
    - pip
    # 2024/05 hmaarrfk/jtilly
    # Test the pip check command with numpy < 2
    # which was included in the requirements file for
    # build time compatibility
    - numpy 1.26.*   # [py == 312]

outputs:
  - name: {{ name|lower }}{{ suffix }}
  - name: {{ name|lower }}{{ suffix }}-cpp
    build:
      string: h{{ PKG_HASH }}_{{ PKG_BUILDNUM }}_{{ build_ext }}
      run_exports:
        - {{ pin_subpackage((name|lower) + suffix + '-cpp', max_pin='x.x.x') }}
    script: install-cpp.sh  # [unix]
    script: install-cpp.bat  # [win]
    requirements:
      build:
        - {{ compiler('c') }}
        - {{ stdlib("c") }}
        - {{ compiler('cxx') }}
        - {{ compiler("cuda") }}  # [cuda_compiler_version != "None"]
      run:
        - __cuda    # [cuda_compiler_version != "None"]
      run_constrained:
        - onnxruntime-cpp <0a0  # [suffix == "-novec"]
    test:
      requires:
        - {{ compiler('cxx') }}
        - {{ stdlib("c") }}
      files:
        - test.cpp
        - run_cpp_test.bat  # [win]
      commands:
        - test -f $PREFIX/include/onnxruntime/core/session/onnxruntime_cxx_api.h  # [unix]
        - test -f $PREFIX/lib/libonnxruntime${SHLIB_EXT}  # [unix]
        - test -f $PREFIX/lib/libonnxruntime_providers_shared${SHLIB_EXT}  # [unix and cuda_compiler_version != "None"]
        - test -f $PREFIX/lib/libonnxruntime_providers_cuda${SHLIB_EXT}  # [unix and cuda_compiler_version != "None"]
        - if not exist %LIBRARY_INC%\\onnxruntime\\core\\session\\onnxruntime_cxx_api.h exit 1  # [win]
        - if not exist %LIBRARY_LIB%\\onnxruntime_conda.lib exit 1  # [win]
        - if not exist %LIBRARY_BIN%\\onnxruntime_conda.dll exit 1  # [win]
        - if not exist %LIBRARY_LIB%\\onnxruntime_providers_shared.lib exit 1  # [win and cuda_compiler_version != "None"]
        - if not exist %LIBRARY_BIN%\\onnxruntime_providers_shared.dll exit 1  # [win and cuda_compiler_version != "None"]
        - if not exist %LIBRARY_LIB%\\onnxruntime_providers_cuda.lib exit 1  # [win and cuda_compiler_version != "None"]
        - if not exist %LIBRARY_BIN%\\onnxruntime_providers_cuda.dll exit 1  # [win and cuda_compiler_version != "None"]
        - $CXX $CXXFLAGS -I$PREFIX/include/ -L$PREFIX/lib/ -lonnxruntime test.cpp                               # [linux]
        - $CXX $CXXFLAGS -I$PREFIX/include/ -L$PREFIX/lib/ -lonnxruntime -Wl,-rpath,$CONDA_PREFIX/lib test.cpp  # [osx]
        - ./a.out  # [unix]
        - call .\run_cpp_test.bat  # [win]

about:
  home: https://github.com/microsoft/onnxruntime/
  summary: cross-platform, high performance ML inferencing and training accelerator
  license: MIT AND BSL-1.0  # mp11 is BSL 1.0
  license_file:
    - LICENSE
    - build-ci/Release/_deps/abseil_cpp-src/LICENSE
    - build-ci/Release/_deps/eigen-src/COPYING.MPL2
    - build-ci/Release/_deps/flatbuffers-src/LICENSE
    - build-ci/Release/_deps/google_nsync-src/LICENSE  # [not win]
    - build-ci/Release/_deps/gsl-src/LICENSE
    - build-ci/Release/_deps/nlohmann_json-src/LICENSE.MIT  # [not unix]
    - build-ci/Release/_deps/onnx-src/LICENSE
    - build-ci/Release/_deps/protobuf-src/LICENSE
    - build-ci/Release/_deps/pytorch_cpuinfo-src/LICENSE
    - build-ci/Release/_deps/re2-src/LICENSE
    - build-ci/Release/_deps/safeint-src/LICENSE

extra:
  recipe-maintainers:
    - xhochy
    - janjagusch
    # jtilly is interested in novec for linux due to numerical discrepancies
    # between eigen's vectorization and onnx's
    - jtilly
    - cbourjau
    # General support for GPUs
    - hmaarrfk
    # Especially interested in Windows
    - traversaro
